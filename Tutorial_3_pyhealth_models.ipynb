{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Preparation**\n",
        "- install pyhealth alpha version"
      ],
      "metadata": {
        "id": "PHPVEkPFKYkw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbz1YJ2nqOSN",
        "outputId": "97b4c89f-13a0-4bfb-ebbd-d04acd4256c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyhealth\n",
            "  Downloading pyhealth-1.1.6-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from pyhealth) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from pyhealth) (0.20.1+cu124)\n",
            "Collecting rdkit>=2022.03.4 (from pyhealth)\n",
            "  Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from pyhealth) (1.6.1)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from pyhealth) (3.4.2)\n",
            "Collecting pandas<2,>=1.3.2 (from pyhealth)\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pandarallel>=1.5.3 (from pyhealth)\n",
            "  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mne>=1.0.3 (from pyhealth)\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting urllib3<=1.26.15 (from pyhealth)\n",
            "  Downloading urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyhealth) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyhealth) (4.67.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->pyhealth) (1.13.1)\n",
            "Collecting dill>=0.3.1 (from pandarallel>=1.5.3->pyhealth)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from pandarallel>=1.5.3->pyhealth) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2,>=1.3.2->pyhealth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2,>=1.3.2->pyhealth) (2025.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit>=2022.03.4->pyhealth) (11.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->pyhealth) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->pyhealth) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->pyhealth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->pyhealth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->pyhealth) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->pyhealth) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->pyhealth) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->pyhealth) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->pyhealth) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.0.3->pyhealth) (3.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.0.3->pyhealth) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.0.3->pyhealth) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas<2,>=1.3.2->pyhealth) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne>=1.0.3->pyhealth) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->pyhealth) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->pyhealth) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->pyhealth) (2025.1.31)\n",
            "Downloading pyhealth-1.1.6-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pandarallel\n",
            "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16674 sha256=d5f5aae9dd1329975fde704f134c835ded667aeede4e981a4c4259d75e82a179\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/c6/5a/829298789e94348b81af52ab42c19d49da007306bbcc983827\n",
            "Successfully built pandarallel\n",
            "Installing collected packages: urllib3, rdkit, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pandarallel, nvidia-cusolver-cu12, mne, pyhealth\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.19 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dill-0.3.9 mne-1.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pandarallel-1.6.5 pandas-1.5.3 pyhealth-1.1.6 rdkit-2024.9.5 urllib3-1.26.15\n"
          ]
        }
      ],
      "source": [
        "!pip install pyhealth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instruction on [pyhealth.models](https://pyhealth.readthedocs.io/en/latest/api/models.html)**\n",
        "- **[README]**: In this package, we provide common deep learning models (e.g., RNN, CNN, Transformer) and special healthcare deep learning models, such as (e.g., RETAIN, SafeDrug, GAMENet). All except some special models (e.g., GAMENet, SafeDrug, MICRON are designed only for drug recommendation task) can be applied to all healthcare prediction tasks. Note that, we have provided two callable methods of each deep learning model:\n",
        "  - Model, such as RNN, CNN, Transformer, RETAIN, **initialized by our dataset object**\n",
        "  - ModelLayer (alternatively), such as RNNLayer, CNNLayer, TransformerLayer, RETAINLayer. Alternatively, **initialized by auxiliary information (specified for each layer)**.\n",
        "\n",
        "- **[Arguments for Model]**:\n",
        "  The arguments for each DL Model follows the arguments below.\n",
        "    - `dataset`: this is the [pyhealth.dataset](https://pyhealth.readthedocs.io/en/latest/api/datasets.html) object. All model specific processing is based on this and is handled within the Model class.\n",
        "    - `feature_keys`: a list of string-based table names, indicating that these tables will be used in the pipeline.\n",
        "    - `label_key`: currently, we only support `label`, defined in task function.\n",
        "    - `mode`: `multiclass`, `multilabel`, or `binary`.\n",
        "    \n",
        "- **[Arguments for the ModelLayer]**:\n",
        "Alternatively, if users do not want to use the [pyhealth.dataset](https://pyhealth.readthedocs.io/en/latest/api/datasets.html) object for initializing Model, then they can choose to call the ModelLayer by preparing inputs following the requirements. The inputs of each ModelLayer can be different (refer to [pyhealth.models](https://pyhealth.readthedocs.io/en/latest/api/models.html). For example, we list the arguments of a RNNLayer below:\n",
        "  - `input_size`: input size of rnn\n",
        "  - `hidden_size`: hidden size of rnn\n",
        "  - `rnn_type`: type of rnn, e.g. GRU, LSTM\n",
        "  - `num_layers`: number of rnn layers\n",
        "  - `dropout`: dropout rate\n",
        "  - `bidirectional`: whether to use bidirectional rnn\n"
      ],
      "metadata": {
        "id": "_1S5rqae7FhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1 & 2: Prepare datasets and task function**\n",
        "- We use **OMOP dataset** for **readmission prediction** task. More details can refer to [Tutorial 1](https://colab.research.google.com/drive/18kbzEQAj1FMs_J9rTGX8eCoxnWdx4Ltn?usp=sharing) and [Tutorial 2](https://colab.research.google.com/drive/1r7MYQR_5yCJGpK_9I9-A10HmpupZuIN-?usp=sharing)"
      ],
      "metadata": {
        "id": "xNNqLWaPM2yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.datasets import MIMIC3Dataset\n",
        "from pyhealth.tasks import readmission_prediction_mimic3_fn\n",
        "\n",
        "dataset = MIMIC3Dataset(\n",
        "        root=\"https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/\",\n",
        "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
        "        code_mapping={\"NDC\": \"ATC\"},\n",
        "        # develop mode is True enables small data load\n",
        "        dev=True,\n",
        ")\n",
        "\n",
        "# specify which task\n",
        "dataset = dataset.set_task(readmission_prediction_mimic3_fn)"
      ],
      "metadata": {
        "id": "ZX2FKvqvNXay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a347fc4a-f60d-4a51-b9ee-5c9b863de0c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Pandarallel will run on 1 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
            "finish basic patient information parsing : 3.275057077407837s\n",
            "finish parsing DIAGNOSES_ICD : 2.3142170906066895s\n",
            "finish parsing PROCEDURES_ICD : 1.2459192276000977s\n",
            "finish parsing PRESCRIPTIONS : 11.686449527740479s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Mapping codes: 100%|██████████| 1000/1000 [00:00<00:00, 1243.54it/s]\n",
            "Generating samples for readmission_prediction_mimic3_fn: 100%|██████████| 1000/1000 [00:00<00:00, 361328.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the format of the first sample\n",
        "dataset.samples[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JVaHgBrRssx",
        "outputId": "c6572b55-fe7d-40cc-b07f-2575437134a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'visit_id': '100183',\n",
              " 'patient_id': '175',\n",
              " 'conditions': [['5990',\n",
              "   '4280',\n",
              "   '2851',\n",
              "   '4240',\n",
              "   '2749',\n",
              "   '9982',\n",
              "   'E8499',\n",
              "   '42831',\n",
              "   '34600']],\n",
              " 'procedures': [['0040', '3931', '7769']],\n",
              " 'drugs': [['N06DA02',\n",
              "   'V06DC01',\n",
              "   'B01AB01',\n",
              "   'A06AA02',\n",
              "   'R03AC02',\n",
              "   'H03AA01',\n",
              "   'J01FA09']],\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3 (Example): Using RETAIN or RETAIN Layer**\n",
        "- Option 1: we choose to initialize the **pyhealth.models.RETAIN** model.\n",
        "- Option 2: we choose to customize a new model with our **pyhealth.models.RETAINLayer**.\n"
      ],
      "metadata": {
        "id": "I-t009qvNzFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1\n",
        "\n",
        "from pyhealth.models import RETAIN\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "model = RETAIN(\n",
        "    # argument 1: call the dataset\n",
        "    dataset=dataset,\n",
        "    # argument 2: use a subset of keys in the data sample format for features\n",
        "    # look up what are available for \"feature_keys\" and \"label_keys\" in dataset.samples[0]\n",
        "    feature_keys=[\"conditions\", \"procedures\"],\n",
        "    # argument 3: use `label` for indicating the prediction label_key\n",
        "    label_key=\"label\",\n",
        "    # argument 4: set the embedding dimension\n",
        "    embedding_dim=128,\n",
        "    # argument 5: what type of tasks, multiclass, multilabel, or binary?\n",
        "    mode=\"binary\",\n",
        ")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "Z9sOQXDJOYTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcc0314-a3b9-4c5d-fae1-a01aea69cbf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RETAIN(\n",
              "  (embeddings): ModuleDict(\n",
              "    (conditions): Embedding(303, 128, padding_idx=0)\n",
              "    (procedures): Embedding(101, 128, padding_idx=0)\n",
              "  )\n",
              "  (linear_layers): ModuleDict()\n",
              "  (retain): ModuleDict(\n",
              "    (conditions): RETAINLayer(\n",
              "      (dropout_layer): Dropout(p=0.5, inplace=False)\n",
              "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
              "      (beta_gru): GRU(128, 128, batch_first=True)\n",
              "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
              "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (procedures): RETAINLayer(\n",
              "      (dropout_layer): Dropout(p=0.5, inplace=False)\n",
              "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
              "      (beta_gru): GRU(128, 128, batch_first=True)\n",
              "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
              "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# option 2\n",
        "\n",
        "from pyhealth.models import RETAINLayer\n",
        "import torch.nn as nn\n",
        "\n",
        "class NewModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int = 64,\n",
        "        hidden_size: int = 128,\n",
        "        num_layers: int = 1,\n",
        "        dropout: float = 0.5,\n",
        "    ):\n",
        "        super(NewModel, self).__init__()\n",
        "\n",
        "        # TODO: implement other module 1\n",
        "        self.module1 = None\n",
        "\n",
        "        # initilize the RNNLayer\n",
        "        self.rnn = RETAINLayer(input_size, dropout)\n",
        "\n",
        "        # TODO: implement other module 2\n",
        "        self.module2 = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.module1(x)\n",
        "        # call the RNNLayer\n",
        "        x = self.rnn(x)\n",
        "        x = self.module2(x)\n",
        "        return x\n",
        "\n",
        "model = NewModel()"
      ],
      "metadata": {
        "id": "NUyhVQtWReZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4 (Example): Using Transformer model**\n",
        "- Option 1: we choose to initialize the **pyhealth.models.Transformer** model.\n",
        "- Option 2: we choose to customize a new model with our **pyhealth.models.TransformerLayer**.\n"
      ],
      "metadata": {
        "id": "JOyi3OwygUOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1\n",
        "\n",
        "from pyhealth.models import Transformer\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "model = Transformer(\n",
        "    # argument 1: call the dataset\n",
        "    dataset=dataset,\n",
        "    # argument 2: use a subset of keys in the data sample format for features\n",
        "    # look up what are available for \"feature_keys\" and \"label_keys\" in dataset.samples[0]\n",
        "    feature_keys=[\"conditions\", \"procedures\"],\n",
        "    # argument 3: use `label` for indicating the prediction label_key\n",
        "    label_key=\"label\",\n",
        "    # argument 4: set the embedding dimension\n",
        "    embedding_dim=128,\n",
        "    # argument 5: what type of tasks, multiclass, multilabel, or binary?\n",
        "    mode=\"binary\",\n",
        ")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnPQOm19hCU8",
        "outputId": "e2f58073-5b89-41ff-a04d-0566950d59c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (embeddings): ModuleDict(\n",
              "    (conditions): Embedding(303, 128, padding_idx=0)\n",
              "    (procedures): Embedding(101, 128, padding_idx=0)\n",
              "  )\n",
              "  (linear_layers): ModuleDict()\n",
              "  (transformer): ModuleDict(\n",
              "    (conditions): TransformerLayer(\n",
              "      (transformer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadedAttention(\n",
              "            (linear_layers): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (attention): Attention()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (feed_forward): PositionwiseFeedForward(\n",
              "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (input_sublayer): SublayerConnection(\n",
              "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "          (output_sublayer): SublayerConnection(\n",
              "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (procedures): TransformerLayer(\n",
              "      (transformer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadedAttention(\n",
              "            (linear_layers): ModuleList(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (1): Linear(in_features=128, out_features=128, bias=False)\n",
              "              (2): Linear(in_features=128, out_features=128, bias=False)\n",
              "            )\n",
              "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
              "            (attention): Attention()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (feed_forward): PositionwiseFeedForward(\n",
              "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "            (activation): GELU(approximate='none')\n",
              "          )\n",
              "          (input_sublayer): SublayerConnection(\n",
              "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "          (output_sublayer): SublayerConnection(\n",
              "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# option 2: build your new model\n",
        "\n",
        "from pyhealth.models import TransformerLayer\n",
        "import torch.nn as nn\n",
        "\n",
        "class NewModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int = 64,\n",
        "        hidden_size: int = 128,\n",
        "        num_layers: int = 1,\n",
        "        dropout: float = 0.5,\n",
        "    ):\n",
        "        super(NewModel, self).__init__()\n",
        "\n",
        "        # you can implement other modules here\n",
        "        self.module1 = None\n",
        "\n",
        "        # initilize the RNNLayer\n",
        "        self.transformer = TransformerLayer(input_size, dropout)\n",
        "\n",
        "        # you can implement other modules here\n",
        "        self.module2 = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.module1(x)\n",
        "        # call the RNNLayer\n",
        "        x = self.transformer(x)\n",
        "        x = self.module2(x)\n",
        "        return x\n",
        "\n",
        "model = NewModel()"
      ],
      "metadata": {
        "id": "l2SznBwghEvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qo-z_ve1hbtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you find it useful, please give us a star ⭐ (fork, and watch) at https://github.com/sunlabuiuc/PyHealth.\n",
        "\n",
        "Thanks very much for your support!"
      ],
      "metadata": {
        "id": "XeJa4S2sbY6a"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}